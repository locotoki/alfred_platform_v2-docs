# Social Intel Agent : Agent Automation Playbook

# Socialâ€‘IntelligenceÂ Agent Â· **Automated YouTube Opportunity Suite**

> Purpose â€“ Run two fullyâ€‘automated test paths that:
> 
> 
> 1. **Nicheâ€‘Scout**Â finds the fastestâ€‘growing, biggest, and most Shortsâ€‘friendly YouTube niches each day.
> 
> 2. **Seedâ€‘toâ€‘Blueprint** turns any seed video (or an autoâ€‘selected hot niche) into a rankedâ€‘channel sheet, a gap report, and a readyâ€‘toâ€‘execute channel strategy.
> 
> Designed for Claude (Anthropic) with shell & Python sandbox enabled. Each indented block is a **single prompt** you paste into Claude. Replace **ALLâ€‘CAPS** placeholders before running.
> 

---

## ğŸ“ŠÂ FlowÂ A â€“Â Nicheâ€‘ScoutÂ (Trendingâ€‘Niche Detector)

| Stage | What it does | Claude Prompt |
| --- | --- | --- |
| **Aâ€‘0 InstallÂ depsÂ & folder** | Oneâ€‘time setâ€‘up | ```text |

Claude, bootstrap Nicheâ€‘Scout env

Shell:
!pip install yt-dlp==2024.3.10 youtube-search-python==1.6.6 pytrends==4.9.0 duckdb umap-learn pandas â€“quiet
!mkdir -p niche_scout
`| | **Aâ€‘1 Daily signal harvest** | â€¢ YouTubeÂ Search â€“ collect topâ€‘100 videos per query.<br>â€¢ GoogleÂ Trends â€“ 7â€‘day RSV for same queries. |`text
Claude, run daily signal harvest (store appendâ€‘only Parquet)

Python:
```python
import duckdb, datetime, json, pathlib, time
from youtubesearchpython import VideosSearch
from pytrends.request import TrendReq

QUERIES = [
â€œnursery rhymesâ€, â€œdiy woodworkingâ€, â€œurban gardeningâ€, â€œai newsâ€, â€œbudget travelâ€,]

py = TrendReq(hl=â€œen-USâ€, tz=0)
rows=[]
today=datetime.date.today().isoformat()
for q in QUERIES:
vs=VideosSearch(q, limit=100).result()[â€˜resultâ€™]
view_sum=sum(int(v.get(â€˜viewCountâ€™,{â€˜textâ€™:â€˜0â€™})[â€˜textâ€™].replace(â€˜,â€™,â€™â€˜)) if isinstance(v.get(â€™viewCountâ€™),dict) else 0 for v in vs)
py.build_payload([q], timeframe=â€˜now 7-dâ€™)
rsv=py.interest_over_time()[q].iloc[-1]
rows.append((today,q,view_sum,rsv))
time.sleep(1)

duckdb.sql(â€œCREATE TABLE IF NOT EXISTS signals(date, query, view_sum, rsv)â€)
duckdb.sql(â€œINSERT INTO signals VALUES (?, ?, ?, ?)â€, rows)
`| | **Aâ€‘2 Score & cluster niches** | Rank attractiveness and group similar queries into canonical niches |`text
Claude, score and cluster signals â†’ trending_niches

Python:
`python import duckdb, pandas as pd, umap, numpy as np, sklearn.cluster as skc sig=duckdb.sql('SELECT * FROM signals').df() latest=sig[sig.date==sig.date.max()] latest['view_rank']=latest.view_sum.rank(ascending=False) latest['rsv_rank']=latest.rsv.rank(ascending=False) latest['score']=0.6*latest['view_rank']+0.4*latest['rsv_rank'] emb=umap.UMAP(n_components=2,random_state=42).fit_transform(pd.get_dummies(latest['query'])) latest[['x','y']]=emb clust=skc.KMeans(n_clusters=min(10,len(latest))).fit(emb) latest['niche']=clust.labels_ latest.to_csv('niche_scout/trending_niches.csv',index=False)` |
| **Aâ€‘3 Digest & surface** | Post the topâ€‘10 hottest niches to Notion / Slack | `text Claude, produce daily Slack digest from trending_niches.csv â€“ summary only.` |

*Caveats*

* YouTubeâ€¯API quotas â€“ ~100Â searches/day.

* GoogleÂ Trends may throttle â€“ include a 1â€‘second sleep per call.

* Clustering is lightweight; switch to topicâ€‘modelling for higher accuracy.

---

## ğŸ—ï¸Â FlowÂ B â€“Â Seedâ€‘toâ€‘BlueprintÂ (Channel Builder)

| Stage | What it does | Claude Prompt |
| --- | --- | --- |
| **Bâ€‘1 Install deps & folder** | *(skip if Aâ€‘0 ran)* | ```text |

Claude, prepare builder env

Shell:
!pip install google-api-python-client==2.126.0 sentence-transformers matplotlib â€“quiet
!mkdir -p builder
`| | **Bâ€‘2 Seed video ingest** | Fetch metadata / transcript |`text
Claude, ingest seed video (manual or auto):

*Manual:* `SEED_URL=https://youtu.be/_UR-l3QI2nE`*Auto:* read trending_niches.csv â†’ pick niche (scoreÂ min) â†’ grab 1st video via search.

Shell:
!yt-dlp -j â€œ$SEED_URLâ€ > builder/seed.json
`| | **Bâ€‘3 Build query list** | Generate niche keyword set |`text
Claude, build QUERY_LIST from seed title & tags using synonyms (â‰¤30 terms). Return list.
`| | **Bâ€‘4 Harvest & rank channels** | Gather channel stats |`text
Claude, harvest channels with YouTubeÂ API (subs, views, 30â€‘day Î”) â†’ builder/top_channels.csv (topÂ 100 by subs).
`| | **Bâ€‘5 Gap analysis** | Compare seed vs rivals |`text
Claude, for each channel scrape 200 titles, perform keyword/rhyme coverage â†’ builder/gap_report.csv
`| | **Bâ€‘6 Strategy blueprint** | Draft channel concept doc |`text
Claude, using top_channels.csv + gap_report.csv + trending_niches.csv, write builder/channel_blueprint.md (positioning, pillars, format mix, 30â€‘day roadmap, AI-production tips, COPPA checklist).
`| | **Bâ€‘7 Package outputs** | Zip deliverables |`text
Claude, zip builder/*.csv builder/channel_blueprint.md â†’ builder/channel_pack.zip
Return link: sandbox:/mnt/data/builder/channel_pack.zip
``` |

*Caveats*

* Comments disabled on Madeâ€‘forâ€‘Kids content â†’ skip comment analytics.

* Whisper transcription optional for music videos.

* Use Prefect/Airflow if you need oneâ€‘click orchestration.

---

## âš ï¸Â General Bestâ€‘Practices

1. **Cache** raw API JSON to cut quota.
2. **Rateâ€‘limit** GoogleÂ Trends calls.
3. **Rotate keys** if scraping.
4. **COPPA & rights**: stick to publicâ€‘domain melodies or licensed tracks.
5. **AI content scale**: metrics `shorts_share`, `template_variability` decide automatedâ€‘output ratio.

---

## âœ…Â Run Order

1. Aâ€‘0â€¯â†’â€¯Aâ€‘3 once (then schedule daily).
2. Trigger FlowÂ B anytime:
    - `Claude, run builder niche=auto` *or*
    - `Claude, run builder video=https://youtu.be/...`
3. Download **channel_pack.zip**, review, and start production.